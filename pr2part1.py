# -*- coding: utf-8 -*-
"""PR2Part1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lYx7MTMY5kcRu2gU5FXlrd4zMKSgTMM-
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from torchvision import datasets, models, transforms

data_transforms = transforms.Compose([
  transforms.Resize((224,224)),
  transforms.RandomHorizontalFlip(),
  transforms.ToTensor(),
  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])

trainset = datasets.CIFAR100(root='.', train = True, transform = data_transforms,
download=True)
testset = datasets.CIFAR100(root='.', train=False, transform = data_transforms,
download=True)

data = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)
#test_dataloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)
print(len(data))

model = models.vgg16(pretrained = True)
print(model)

num_in_ftrs = model.classifier[6].in_features
print(num_in_ftrs)

num_cls = 100
model.classifier[6] = nn.Linear(num_in_ftrs, num_cls, bias=True)

for param in model.parameters(): # freeze all the layers
  param.requires_grad = False
for param in model.classifier[6].parameters(): # unfreeze the last linear layer.
  param.requires_grad = True

num_epochs = 10

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

criterion = nn.CrossEntropyLoss()

optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

for i in range(10):
  print(i)
  for j, batch in enumerate(data):
    images, labels = batch
    images = images.to(device)
    labels = labels.to(device)
    optimizer.zero_grad()
    outputs = model(images)
    loss = criterion(outputs,labels)
    loss.backward()
    optimizer.step()
  scheduler.step()
  torch.save(model.state_dict(), 'best_model.pth')
print("Done Training")

model.load_state_dict(torch.load('best_model.pth'))
model.eval()

data = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)

preds_array = []
labels_array = []
for i in range(1):
  for j, batch in enumerate(data):
    images, labels = batch
    images = images.to(device)
    labels = labels.to(device)
    outputs = model(images)
    _, preds = torch.max(outputs, 1)
    preds_array += preds
    labels_array += labels
print("Done Testing")

corr_counter = 0
num_samps = len(preds_array)
for i in range(len(preds_array)):
  if preds_array[i].item() == labels_array[i].item():
    corr_counter += 1


accuracy = corr_counter/num_samps
print(accuracy)